{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB Reviews - RNN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwWD827TPweV168XGZEwrH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akilesh1989/Running-TF-models-in-BigQuery/blob/main/IMDB_Reviews_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iVk9Xkn-SOi"
      },
      "source": [
        "## Creating a Tensorflow model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX4WshwO-X7Q"
      },
      "source": [
        "The following code creates a tensorflow model that predicts if a movie is good or bad. 1 stands for good and 0 stands for bad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1MAJ93_Ptol"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYKim0TKQXPg"
      },
      "source": [
        "train_data, validation_data, test_data = tfds.load(\n",
        "    name=\"imdb_reviews\", \n",
        "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
        "    as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqHxYn8cPbPY"
      },
      "source": [
        "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[],\n",
        "dtype=tf.string, trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WDUvadPPqkU"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  hub_layer,\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UlP3p5TQKqu"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnlIy1EAQr-V"
      },
      "source": [
        "history = model.fit(train_data.shuffle(10000).batch(512),\n",
        "                    epochs=20,\n",
        "                    validation_data=validation_data.batch(512),\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ABaUUImQ2DC"
      },
      "source": [
        "results = model.evaluate(test_data.batch(512), verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6ADpWENP9jL"
      },
      "source": [
        "model.save('model_v1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9sC6JfQ_XrT"
      },
      "source": [
        "## Move the model to GCS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lI04Ve5R1Rp"
      },
      "source": [
        "from google.colab import auth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH8cG9U5SorZ"
      },
      "source": [
        "!curl https://sdk.cloud.google.com | bash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM5Rq9hbSsiy"
      },
      "source": [
        "!gcloud init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx_4aLXtSvHl"
      },
      "source": [
        "BUCKET = \"akilesh-tensorflow-models\"\n",
        "!gsutil cp -r model_v1 gs://{BUCKET}/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npZBTjN5_3Tw"
      },
      "source": [
        "## Convert train, test and validation datasets to CSV and move them to GCS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9a9Cmi_U7Kc"
      },
      "source": [
        "def to_csv(data, filename):\n",
        "  \"\"\"Takes TF Dataset and writes it to a (local) CSV file. Make sure the dataset is not too large!\"\"\"\n",
        "  import csv\n",
        "\n",
        "  data_list = [{ 'text': text.decode('utf-8'), 'label': label } for text, label in data.as_numpy_iterator()]\n",
        "  filename = '{}.csv'.format(filename)\n",
        "\n",
        "  with open(filename, 'w') as f:\n",
        "    writer = csv.DictWriter(f, data_list[0].keys())\n",
        "    writer.writeheader()\n",
        "    writer.writerows(data_list)\n",
        "\n",
        "train_data, validation_data, test_data = tfds.load(\n",
        "    name=\"imdb_reviews\", \n",
        "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
        "    as_supervised=True)\n",
        "\n",
        "to_csv(train_data, 'train')\n",
        "to_csv(validation_data, 'validation')\n",
        "to_csv(test_data, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1GCoSBTVhKv"
      },
      "source": [
        "BUCKET = 'datasets-akilesh' # use your own bucket name here\n",
        "!gsutil cp train.csv gs://{BUCKET}/\n",
        "!gsutil cp validation.csv gs://{BUCKET}/\n",
        "!gsutil cp test.csv gs://{BUCKET}/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlT5xQsx4Uh1"
      },
      "source": [
        "## Create and load test data into the tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRGHRxN3AZGc"
      },
      "source": [
        "### Authenticate COLAB to work with BQ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFFYF3XVAXaF"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RahjJfid34c7"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = \"adept-chemist-223208\"\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "dataset_id = \"imdb\"\n",
        "table_name = \"test\"\n",
        "table_id = f\"{project_id}.{dataset_id}.{table_name}\"\n",
        "\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    schema=[\n",
        "        bigquery.SchemaField(\"text\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"label\", \"INTEGER\")\n",
        "    ],\n",
        "    skip_leading_rows=1,\n",
        "    write_disposition=\"WRITE_TRUNCATE\",\n",
        "    # The source format defaults to CSV, so the line below is optional.\n",
        "    source_format=bigquery.SourceFormat.CSV,\n",
        ")\n",
        "BUCKET = \"datasets-akilesh\"\n",
        "file_name = \"test.csv\"\n",
        "uri = f\"gs://{BUCKET}/{file_name}\"\n",
        "\n",
        "load_job = client.load_table_from_uri(\n",
        "    uri, table_id, job_config=job_config\n",
        ")  # Make an API request.\n",
        "\n",
        "load_job.result()  # Waits for the job to complete.\n",
        "\n",
        "destination_table = client.get_table(table_id)  # Make an API request.\n",
        "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4Jr6EBJ5u4Z"
      },
      "source": [
        "## Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjORHNvT5JYd"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "MODEL_NAME = \"movie_classification_model\"\n",
        "\n",
        "query = f\"\"\"\n",
        "    CREATE OR REPLACE MODEL imdb.{MODEL_NAME}\n",
        "    OPTIONS (MODEL_TYPE='TENSORFLOW',  MODEL_PATH=\"gs://akilesh-tensorflow-models/model_v1/*\")\n",
        "\n",
        "\"\"\"\n",
        "query_job = client.query(query)  # Make an API request.\n",
        "\n",
        "print(\"Loading the model into BigQuery:\")\n",
        "for row in query_job:\n",
        "    # Row values can be accessed by field name or index.\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFbojoMq64bc"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy0Rq5T16roC"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"\n",
        "    WITH\n",
        " logits AS (\n",
        " SELECT\n",
        "   *\n",
        " FROM\n",
        "   ML.PREDICT( MODEL imdb.{MODEL_NAME},\n",
        "     (\n",
        "     SELECT\n",
        "       text AS keras_layer_input,\n",
        "       label\n",
        "     FROM\n",
        "       `imdb.test` ) ) ),\n",
        " predictions AS (\n",
        " SELECT\n",
        "   CAST(1.0 / (1.0 + EXP(-dense_1)) > 0.5 AS INT64) AS pred,\n",
        "   label\n",
        " FROM\n",
        "   logits )\n",
        "SELECT\n",
        " SUM(pred * label + (1 - pred)*(1 - label))/COUNT(*)*100 AS accuracy\n",
        "FROM\n",
        " predictions\n",
        "\"\"\"\n",
        "query_job = client.query(query)  # Make an API request.\n",
        "\n",
        "print(\"Evaluating the model:\")\n",
        "for row in query_job:\n",
        "    # Row values can be accessed by field name or index.\n",
        "    print(row)\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpZe04_TcxQG"
      },
      "source": [
        "### Understanding the SQL code for prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np5sB_FZc2uf"
      },
      "source": [
        "In the first step we "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXxm7C7UAqbD"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"SELECT\n",
        "   *\n",
        " FROM\n",
        "   ML.PREDICT( MODEL imdb.{MODEL_NAME},\n",
        "     (\n",
        "     SELECT\n",
        "       text AS keras_layer_input,\n",
        "       label\n",
        "     FROM\n",
        "       `imdb.test` ) )\n",
        "\"\"\"\n",
        "query_job = client.query(query)  # Make an API request.\n",
        "\n",
        "print(\"Evaluating the model:\")\n",
        "for row in query_job:\n",
        "    # Row values can be accessed by field name or index.\n",
        "    print(row)\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws-FXe0qByxd"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"WITH\n",
        "  logits AS (\n",
        "  SELECT\n",
        "    *\n",
        "  FROM\n",
        "    ML.PREDICT( MODEL imdb.{MODEL_NAME},\n",
        "      (\n",
        "      SELECT\n",
        "        text AS keras_layer_input,\n",
        "        label\n",
        "      FROM\n",
        "        `imdb.test` ) ) ),\n",
        "  predictions AS (\n",
        "  SELECT\n",
        "    CAST(1.0 / (1.0 + EXP(-dense_1)) > 0.5 AS INT64) AS pred,\n",
        "    label\n",
        "  FROM\n",
        "    logits )\n",
        "SELECT * FROM predictions\n",
        "\"\"\"\n",
        "query_job = client.query(query)  # Make an API request.\n",
        "\n",
        "print(\"Evaluating the model:\")\n",
        "for row in query_job:\n",
        "    # Row values can be accessed by field name or index.\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hacAJcdA7c0U"
      },
      "source": [
        "## Making predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wbNGb93FPKV"
      },
      "source": [
        "Imdb website: https://www.imdb.com/?ref_=nv_home"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykupOG1B7xxr"
      },
      "source": [
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "\n",
        "\n",
        "sample_reviews = pd.DataFrame({\n",
        "    'text': [\n",
        "             'This was an awful movie',\n",
        "             'Excellent movie',\n",
        "             'Not too bad',\n",
        "             'Good background score but terrible plot',\n",
        "             'As a former Erasmus student I enjoyed this film very much. It was so realistic and funny. It really picked up the spirit that exists among Erasmus students. I hope, many other students will follow this experience, too. However, I wonder if this movie is all that interesting to watch for people with no international experience. But at least one of my friends who has never gone on Erasmus also enjoyed it very much. I give it 9 out of 10.',\n",
        "             'As a film lover I found the movie to be very enjoyable. The screenplay could have been better but the overall experience was excellent.',\n",
        "             'I have never ever seen a movie like this before. The acting was terrible and you call that CGI. Duh.'\n",
        "             \"I get why some people hate this . It's because of the political message and how some people think that you need get empathy for Arthur's madness. But come on that is not the point and it will never be. Enjoy this masterpiece because Joaquin Phoenix and Todd Phillips overdid themselves with this movie . The acting,music and cinematography are just amazing ! Please enjoy the movie without overthinking it.\"\n",
        "             \"I've lost count of the number of times I have seen this movie, but it is more than 20. It has to be one of the best movies ever made. It made me take notice Morgan Freeman and Tim Robbins like I had never noticed any actors before. I have from a very young age been a huge fan of anything Stephen King writes and had already read the short story that this movie is based on years prior to seeing this movie. Not everything Stephen King has written that gets turned into a movie comes out well, but this is as close to perfection as it gets and has everything you could ever want in a movie.Something that is outstanding is the fact that it has no real action, no special effects and no gimmicks. 99% of the movie is just men in a prison uniforms talking. Yet it absolutely hooks you almost from the beginning and has you glued to the screen to the end.For me what really makes this film one of the best is the message of eternal hope it conveys throughout. The never ever give up hope attitude of the main character so well conveyed by Tim Robbins. The ending is just spine tingling every time I see it, no matter how many times I have seen it.Brilliant, brilliant movie and a must see for everyone.\"\n",
        "             ]\n",
        "})\n",
        "sample_reviews\n",
        "sample_reviews.to_csv(\"sample.csv\", index=False)\n",
        "\n",
        "\n",
        "!gsutil cp sample.csv gs://{BUCKET}/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_vOhltn771e"
      },
      "source": [
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "dataset_id = \"imdb\"\n",
        "table_name = \"samples\"\n",
        "table_id = f\"{project_id}.{dataset_id}.{table_name}\"\n",
        "\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    schema=[\n",
        "        bigquery.SchemaField(\"text\", \"STRING\")\n",
        "    ],\n",
        "    skip_leading_rows=1,\n",
        "    write_disposition=\"WRITE_TRUNCATE\",\n",
        "    # The source format defaults to CSV, so the line below is optional.\n",
        "    source_format=bigquery.SourceFormat.CSV,\n",
        ")\n",
        "BUCKET = \"datasets-akilesh\"\n",
        "file_name = \"sample.csv\"\n",
        "uri = f\"gs://{BUCKET}/{file_name}\"\n",
        "\n",
        "load_job = client.load_table_from_uri(\n",
        "    uri, table_id, job_config=job_config\n",
        ")  # Make an API request.\n",
        "\n",
        "load_job.result()  # Waits for the job to complete.\n",
        "\n",
        "destination_table = client.get_table(table_id)  # Make an API request.\n",
        "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGcmNeik7Cf1"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"\n",
        "    WITH\n",
        "\n",
        "logistic_predictions AS (\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.PREDICT(MODEL imdb.{MODEL_NAME}, (\n",
        "    SELECT\n",
        "      text AS keras_layer_input,\n",
        "      text\n",
        "    FROM\n",
        "      `imdb.{table_name}` ))),\n",
        "\n",
        "predictions AS (\n",
        "  SELECT\n",
        "    text,\n",
        "    CAST(1.0 / (1.0 + EXP(-dense_1)) > 0.5 AS INT64) AS pred\n",
        "  FROM\n",
        "    logistic_predictions)\n",
        "SELECT * FROM predictions\n",
        "\"\"\"\n",
        "query_job = client.query(query)  # Make an API request.\n",
        "\n",
        "print(\"Making predictions:\")\n",
        "for row in query_job:\n",
        "    # Row values can be accessed by field name or index.\n",
        "    print(row[0], row[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBitIbJkEbeL"
      },
      "source": [
        "References: https://medium.com/g-company/custom-model-on-bigquery-ml-45db14aa887a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-2hEugp7kn2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}